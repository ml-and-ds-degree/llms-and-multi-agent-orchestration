{
    "name": "LLMs and Multi-Agent Orchestration",
    "build": {
        "dockerfile": "Dockerfile",
        "context": "."
    },
    "customizations": {
        "vscode": {
            "settings": {
                "terminal.integrated.defaultProfile.linux": "zsh",
                "python.defaultInterpreterPath": "/usr/bin/python3",
                "terminal.integrated.stickyScroll.enabled": false
            },
            "extensions": [
                "ms-python.python",
                "ms-python.vscode-pylance",
                "charliermarsh.ruff",
                "openai.chatgpt",
                "docker.docker",
                "ms-azuretools.vscode-containers",
                "tamasfe.even-better-toml"
            ]
        }
    },
    "features": {
        "ghcr.io/devcontainers/features/common-utils:2": {
            "installZsh": true,
            "installOhMyZsh": true,
            "configureZshAsDefaultShell": true
        },
        "ghcr.io/devcontainers-extra/features/zsh-plugins": {
            "plugins": "uv"
        },
        "ghcr.io/devcontainers/features/docker-in-docker": {}
    },
    "forwardPorts": [
        11434
    ],
    "postCreateCommand": {
        "installPython": "uv python install 3.13",
        "setupOllama": "nohup ollama serve > /tmp/ollama-serve.log 2>&1 & sleep 5 && ollama pull llama3.2:latest",
        "welcome": "echo 'Development container ready! Python 3.13 and Ollama are configured.'"
    },
    "remoteUser": "root"
}